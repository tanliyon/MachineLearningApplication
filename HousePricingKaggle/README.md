<h1> House Prices: Advanced Regression Techniques </h1>
<p>Available online at: https://www.kaggle.com/c/house-prices-advanced-regression-techniques<p>

<p>Comprehensive data exploration and feature engineering was done to obtain a clean dataset to work on.<p>
<p>Many techniques like log-transform to reduce skewness, intelligent guess for missing datas, dropping similar features, label encoding and dummy variables were done to ensure that the dataset is optimum for the SK Algorithms</p>
<p>Then, ensembled learning was used to combine many various linear regression techniques like lasso, elastic net, gradient boost, XgBoost, and LightGBM to produce the prediction</p>

<h2>Result</h2>
<p>Ranked top 14% with RMS Error of 0.11651<p>

<p>Credits to these kernels for guiding me through.</p>
<li>https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python</li>
<li>https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard</li>
<li>https://www.kaggle.com/apapiu/regularized-linear-models</li>
